strfinder <- strfinder[strfinder$start != -1 & strfinder$end != -1,]
# if two STRs in the same individual overlap, one of them is clearly wrong. Discover such cases and eliminate them (we should institute this in STRfinder itself before printing results perhaps...?)
strfinder.grange <- makeGRangesFromDataFrame(df = strfinder)
overlaps <- findOverlaps(strfinder.grange, strfinder.grange)
overlaps <- overlaps[queryHits(overlaps) != subjectHits(overlaps)]
exclude <- unique(queryHits(overlaps))
length(exclude) # booting out 684 loci for that reason...not negligible
strfinder <- strfinder[-1 * exclude,]
# number of STRs remaining...
nrow(strfinder) # 9297
# note that we haven't excluded cases where e.g. a reported STR overlaps with TWO STRs on the reference list...going to ignore these for now
# change the strfinder chromosome names to match those on the reference list...
strfinder$chr <- paste("chr", strfinder$chr, sep = '')
# overlap the STRs located by STRfinder with the STRs on the reference list
strfinder.granges <- makeGRangesFromDataFrame(df = strfinder)
ref.granges <- makeGRangesFromDataFrame(df = ref)
overlaps <- findOverlaps(strfinder.granges, ref.granges)
# each row of strfinder_overlapping overlaps with the corresponding row of ref_overlapping
strfinder_overlapping <- strfinder[queryHits(overlaps),]
ref_overlapping <- ref[subjectHits(overlaps),]
# how often do the STR repeat units match??
# need to define a few functions for this:
generate_phases <- function(x) {
# e.g., input: AGG
# returns: c(AGG, GGA, GAG)
individual_chars <- strsplit(x, "")[[1]]
phases <- c()
for(i in 1:nchar(x)) {
phases <- c(phases, ifelse(i == 1, x, paste(c(individual_chars[i:nchar(x)], individual_chars[1:i-1]), collapse = "")))
}
return(phases)
}
# test generate_phases
# generate_phases("A")
# generate_phases("AC")
# generate_phases("ACG")
# seems to work
repeat_units_match <- function(unit_1, unit_2) {
# tests if unit_1 matches unit_2 or it's reverse complement, including phases...
# e.g., unit_1 = "AG" and unit_2 = "TC" will return true, because "AG" --> reverse complement --> "CT" --> phase --> "TC"
unit_2.rc <- as.character(reverseComplement(DNAString(unit_2)))
unit_2_phases <- generate_phases(unit_2)
unit_2.rc_phases <- generate_phases(unit_2.rc)
if(unit_1 %in% c(unit_2_phases, unit_2.rc_phases)) {
return(T)
} else {
return(F)
}
}
# test
# repeat_units_match("AG", "TC")
# repeat_units_match("AG", "TT")
# seems to work
reported_repeat_unit_confirmed <- sapply(1:nrow(strfinder_overlapping), function(x){repeat_units_match(strfinder_overlapping$repeat_unit[x], ref_overlapping$repeat_unit[x])})
# get the counts
table(reported_repeat_unit_confirmed)
# so in the vast, vast majority of cases, the reported repeat unit matches the repeat unit of the overlapping reference STR
# how often do the allele types match?
# read length was 101 bp.  So 101 bp or greater is a B allele; less than 101 is an A allele
# assign the types...noting that we need to convert to base pairs
ref_overlapping$L1_bp <- nchar(ref_overlapping$repeat_unit) * ref_overlapping$L1
ref_overlapping$L2_bp <- nchar(ref_overlapping$repeat_unit) * ref_overlapping$L2
ref_overlapping$type_1 <- ifelse(ref_overlapping$L1_bp>=101, "B", "A")
ref_overlapping$type_2 <- ifelse(ref_overlapping$L2_bp>=101, "B", "A")
ref_overlapping$allele_type <- apply(ref_overlapping[,c("type_1", "type_2")], 1, function(y){paste(sort(y), collapse = "")})
# now check how often the allele types match...make an informative table
allele_types <- as.data.frame(cbind(ref_overlapping[,c("allele_type")], strfinder_overlapping[,c("STR_type")]))
colnames(allele_types) <- c("ref", "strfinder")
allele_types <- ddply(allele_types, .(ref, strfinder), summarize, count = length(ref))
allele_types # this table indicates how many times an STR of type ref was called as "XX" by STRfinder.
# For example, there were 22 cases in which an STR of type "AB" was wrongly called as "AA" by STRfinder.
library("ggplot2")
library("gridExtra")
library("plyr")
BASE_DIR <- "/Users/peterorchard/Google Drive/Rotations/sartor/from_bcs2/interaction_lists/"
interactions <- ""
for(file in list.files(BASE_DIR, pattern = ".interactions")) {
tmp <- read.table(paste(BASE_DIR, file, sep = '/'), head = F, as.is = T, sep = '\t')
tmp <- tmp[,1:6]
colnames(tmp) <- paste(c("chromosome", "start", "end"), c(rep(1, 3), rep(2, 3)), sep = "_")
tmp <- tmp[tmp$chromosome_1==tmp$chromosome_2,]
tmp$experiment <- gsub(".interactions", "", file)
if(is.data.frame(interactions)) {
interactions <- rbind(interactions, tmp)
} else {
interactions <- tmp
}
}
head(interactions)
interaction_counts <- ggplot(interactions) + geom_bar(aes(experiment, fill = experiment), stat = "count")
interaction_counts
library("ggplot2")
library("gridExtra")
library("plyr")
BASE_DIR <- "/Users/peterorchard/Google Drive/Rotations/sartor/from_bcs2"
# load up the current information...
enhancers <- read.table(paste(BASE_DIR, "current.loci", sep = '/'), head = F, as.is = T, sep = '\t')
colnames(enhancers) <- c("chromosome", "start", "end", "class")
enhancers <- enhancers[enhancers$class == "enhancer", c("chromosome", "start", "end")]
enhancers$category <- "current"
for(file in list.files(BASE_DIR, pattern = "chromhmm.*.loci")) {
tmp <- read.table(paste(BASE_DIR, file, sep = '/'), head = F, as.is = T, sep = '\t')
colnames(tmp) <- c("chromosome", "start", "end", "class")
tmp <- unique(tmp[tmp$class == "enhancer", c("chromosome", "start", "end")])
category <- gsub("chromhmm", "HMM", file)
category <- gsub("dnase", "DNASE", category)
category <- gsub("_", "+", category)
category <- gsub(".loci", "", category)
tmp$category <- category
enhancers <- rbind(enhancers, tmp)
}
enhancers$length <- enhancers$end - enhancers$start
enhancer_counts <- ggplot(enhancers) + geom_bar(aes(category), stat = "count") + theme(axis.text.x = element_text(angle = 90))
enhancer_counts + ggtitle("Number of enhancers")
lengths <- ggplot(enhancers) + geom_histogram(aes(x = length)) + facet_wrap( ~ category) + xlim(c(0, 10000))
lengths + ggtitle("Enhancer lengths")
king_cruises <- read.table("/Users/peterorchard/Documents/king_cruises.csv", head = T, as.is = T, sep = ",")
head(king_cruises)
king_cruises <- king_cruises[,1]
head(king_cruises)
cosmetics <- read.table("/Users/peterorchard/Documents/cosmetic_sales.csv", head = T, as.is = T, sep = ",")
head(cosmetics)
colnames(cosmetics) <- c("salesperson", "purchase")
cosmetics <- read.table("/Users/peterorchard/Documents/cosmetic_sales.csv", head = T, as.is = T, sep = ",")
cosmetics <- cosmetics[,c(1,2)]
colnames(cosmetics) <- c("salesperson", "purchase")
cosmetics <- read.table("/Users/peterorchard/Documents/cosmetic_sales.csv", head = T, as.is = T, sep = ",")
cosmetics <- cosmetics[,c(1,2)]
colnames(cosmetics) <- c("salesperson", "purchase")
head(cosmetics)
grady <- read.table("/Users/peterorchard/Documents/king_cruises.csv", head = T, as.is = T, sep = ",")
head(grady)
grady <- read.table("/Users/peterorchard/Documents/grady_white.csv", head = T, as.is = T, sep = ",")
head(grady)
grady <- read.table("/Users/peterorchard/Documents/grady_white.csv", head = T, as.is = T, sep = ",")
grady <- grady[,c(2, 3, 4)]
head(grady)
grady <- read.table("/Users/peterorchard/Documents/grady_white.csv", head = T, as.is = T, sep = ",")
grady <- grady[,c(2, 3, 4)]
colnames(grady) <- c("expenditures", "state", "encoding")
head(grady)
head(cosmetics)
cosmetics$encoding <- ifelse(cosmetics$purchase == "Yes", T, F)
head(cosmetics)
cosmetics$encoding <- ifelse(cosmetics$purchase == "Yes", T, F)
n <- nrow(cosmetics)
se <- sqrt((0.3) * (1-0.3) / n)
se
n
test.statistic <- (sum(cosmetics$encoding) - 0.3) / se
test.statistic
se
cosmetics$encoding <- ifelse(cosmetics$purchase == "Yes", T, F)
# calculate the standard error
# dealing with a proportion so will use the z-dist
n <- nrow(cosmetics)
se <- sqrt((0.3) * (1-0.3) / n)
test.statistic <- ((sum(cosmetics$encoding) / n) - 0.3) / se
test.statistic
test.statistic
(sum(cosmetics$encoding) / n) - 0.3)
(sum(cosmetics$encoding) / n) - 0.3
sum(cosmetics$encoding) / n)
sum(cosmetics$encoding) / n
test.statistic
pnorm(q = test.statistic, mean = 0, sd = 1, lower.tail = F)
pnorm(q = sum(cosmetics$encoding) / n, mean = 0.3, sd = se, lower.tail = F)
pnorm(q = test.statistic, mean = 0, sd = 1, lower.tail = F)
pnorm(q = sum(cosmetics$encoding) / n, mean = 0.3, sd = se, lower.tail = F)
head(king_cruises)
sd
sd(king_cruises)
n <- length(king_cruises)
se <- sd(king_cruises) / sqrt(n)
sd
se
test.statistic <- (mean(king_cruises) - 90) / se
test.statistic
mean(king_cruises)
pt(q = test.statistic, df = n - 1)
cosmetics$encoding <- ifelse(cosmetics$purchase == "Yes", T, F)
n <- nrow(cosmetics)
binom.test(x = sum(cosmetics$encoding), n = n, p = 0.3, alternative = "greater")
n
sum(cosmetics$encoding)
binom.test(x = sum(cosmetics$encoding) + 1, n = n, p = 0.3, alternative = "greater")
cosmetics$encoding <- ifelse(cosmetics$purchase == "Yes", T, F)
# calculate the standard error
# dealing with a proportion so will use the z-dist
n <- nrow(cosmetics)
se <- sqrt((0.3) * (1-0.3) / n)
test.statistic <- ((sum(cosmetics$encoding) / n) - 0.3) / se
test.statistic
pnorm(q = test.statistic, mean = 0, sd = 1, lower.tail = F)
head(grady)
n <- nrow(grady)
tail(grady)
se <- sd(grady$expenditures) / n
n <- nrow(grady)
se <- sd(grady$expenditures) / n
n <- nrow(grady)
se <- sd(grady$expenditures) / sqrt(n)
test.statistic <- (mean(grady$expenditures) - 120) / se
test.statistic
pt(q = test.statistic, df = n - 1)
pt(q = test.statistic, df = n - 1, lower.tail = F)
head(grady)
grady[grady$encoding=="MA",]
grady[grady$encoding=="1",]
p_bar <- sum(grady$encoding) / n
p_bar
n <- nrow(grady)
p_bar <- sum(grady$encoding) / n
se <- sqrt((0.25) * (1 - 0.25) / n)
se
p_bar
test.statistic <- (p_bar - 0.25) / se
test.statistic
n
p_bar
se
pnorm(q = test.statistic, mean = 0, sd = 1, lower.tail = F)
king_cruises <- read.table("/Users/peterorchard/Documents/king_cruises.csv", head = T, as.is = T, sep = ",")
king_cruises <- king_cruises[,1]
head(king_cruises)
cosmetics <- read.table("/Users/peterorchard/Documents/cosmetic_sales.csv", head = T, as.is = T, sep = ",")
cosmetics <- cosmetics[,c(1,2)]
colnames(cosmetics) <- c("salesperson", "purchase")
head(cosmetics)
grady <- read.table("/Users/peterorchard/Documents/grady_white.csv", head = T, as.is = T, sep = ",")
grady <- grady[,c(2, 3, 4)]
colnames(grady) <- c("expenditures", "state", "encoding")
head(grady)
cosmetics$encoding <- ifelse(cosmetics$purchase == "Yes", T, F)
head(cosmetics)
sum(cosmetics$encoding) / n
cosmetics$encoding <- ifelse(cosmetics$purchase == "Yes", T, F)
n <- nrow(cosmetics)
cosmetics$encoding <- ifelse(cosmetics$purchase == "Yes", T, F)
sum(cosmetics$encoding) / n
se <- sqrt((0.3) * (1-0.3) / n)
se
cosmetics$encoding <- ifelse(cosmetics$purchase == "Yes", T, F)
# calculate the standard error
# dealing with a proportion so will use the z-dist
n <- nrow(cosmetics)
se <- sqrt((0.3) * (1-0.3) / n)
test.statistic <- ((sum(cosmetics$encoding) / n) - 0.3) / se
test.statistic
n <- length(king_cruises)
sd(king_cruises)
n <- length(king_cruises)
se <- sd(king_cruises) / sqrt(n)
se
test.statistic <- (mean(king_cruises) - 90) / se
test.statistic
pt(q = test.statistic, df = n - 1)
qt(p = 0.05, df = 74)
se
n <- nrow(grady)
se <- sd(grady$expenditures) / sqrt(n)
test.statistic <- (mean(grady$expenditures) - 120) / se
test.statistic
se
pt(q = test.statistic, df = n - 1, lower.tail = F)
test.statistic <- (120.76 - 120) / se
pt(q = test.statistic, df = n - 1, lower.tail = F)
n <- nrow(grady)
se <- sd(grady$expenditures) / sqrt(n)
test.statistic <- (mean(grady$expenditures) - 120) / se
test.statistic <- (120.76 - 120) / se
pt(q = test.statistic, df = n - 1, lower.tail = F)
n
qt(p = 0.95, df = 1343)
n
test.statistic <- (121.81 - 120) / se
pt(q = test.statistic, df = n - 1, lower.tail = F)
1 / 70
17 / 70
18 / 70
binom.test(x = 510, n = 1000, p = 0.5)
binom.test(x = 510, n = 1000, p = 0.5, alternative = "greater")
binom.test(x = 520, n = 1000, p = 0.5, alternative = "greater")
binom.test(x = 1040, n = 2000, p = 0.5, alternative = "greater")
binom.test(x = 1050, n = 2000, p = 0.5, alternative = "greater")
opts <- list("/Users/peterorchard/Google Drive/Rotations/sartor/enhancer_definitions/ldef_hg19_5kb_and_enhancers_2kb.bed", "/Users/peterorchard/Google Drive/Rotations/sartor/ENCODE_chipseq/wgEncodeAwgTfbsSydhHuvecMaxUniPk.narrowPeak.gz")
names(opts) <- c("locus_definitions", "chipseq")
pwd
getwd()
setwd("/Users/peterorchard/Google Drive/Rotations/sartor/improving_enhancer_definitions/chipenrich/")
opts <- list("chromhmm_dnase.2000.E.wgEncodeAwgTfbsBroadDnd41CtcfUniPk.narrowPeak_results.tab,chromhmm_dnase.2000.P2P.wgEncodeAwgTfbsBroadDnd41CtcfUniPk.narrowPeak_results.tab,current.wgEncodeAwgTfbsBroadDnd41CtcfUniPk.narrowPeak_results.tab",
"DNase.2000.E,DNase.2000.P2P,current")
names(opts) <- c("results", "labels")
results_files <- strsplit(opts$results, ",")[[1]]
if (length(results_files) < 2) {
stop("At least two results files must be passed to --results (as a comma-separated list)")
}
labels <- strsplit(opts$labels, ",")[[1]]
if (length(labels) != length(results_files)) {
stop("The number of labels must match the number of results files")
}
suppressPackageStartupMessages(library("plyr"))
suppressPackageStartupMessages(library("ggplot2"))
all <- ""
for(i in results_files) {
tmp <- read.table(i, head = T, as.is = T, sep = "\t")
tmp <- tmp[,c("Geneset.ID", "Description", "P.value")]
tmp$P.value <- -1 * log10(tmp$P.value)
colnames(tmp) <- c("Geneset.ID", "Description", labels[match(i, results_files)])
if(is.data.frame(all)) {
all <- join(all, tmp)
} else {
all <- tmp
}
}
head(all)
tail(all)
all <- all[,!colnames(all) %in% c("Geneset.ID", "Description")]
suppressPackageStartupMessages(library("reshape2"))
suppressPackageStartupMessages(library("tidyr"))
tmp <- tidyr::gather(all, key = category, value, all[,-1 * grep("current", colnames(all))])
head(all[,-1 * grep("current", colnames(all))])
tmp <- tidyr::gather(all, key = category, value, grep("current", colnames(all), invert = T))
head(tmp)
p <- ggplot(all) + geom_point(aes(x = current, y = value)) + facet_wrap(~ category)
p
p <- ggplot(all) + geom_point(aes(x = current, y = value)) + facet_wrap(category ~)
p
p <- ggplot(all) + geom_point(aes(x = current, y = value)) + facet_wrap( ~ category)
p
all <- tidyr::gather(all, key = category, value, grep("current", colnames(all), invert = T))
p <- ggplot(all) + geom_point(aes(x = current, y = value)) + facet_wrap( ~ category)
p
p <- ggplot(all) + geom_point(aes(x = current, y = value)) + facet_wrap( ~ category) + geom_abline(slope = 1, intercept = 0)
p
p <- ggplot(all) + geom_point(aes(x = current, y = value)) + facet_wrap( ~ category) + geom_abline(slope = 1, intercept = 0, color = "red", type = "dashed")
p
p <- ggplot(all) + geom_point(aes(x = current, y = value)) + facet_wrap( ~ category) + geom_abline(aes(color = "red", type = "dashed"), slope = 1, intercept = 0)
p
head(all)
sum(is.na(all$current))
sum(is.na(all$value))
all <- ""
for(i in results_files) {
tmp <- read.table(i, head = T, as.is = T, sep = "\t")
tmp <- tmp[,c("Geneset.ID", "Description", "P.value")]
tmp$P.value <- -1 * log10(tmp$P.value)
colnames(tmp) <- c("Geneset.ID", "Description", labels[match(i, results_files)])
if(is.data.frame(all)) {
all <- join(all, tmp)
} else {
all <- tmp
}
}
head(all)
all <- ""
for(i in results_files) {
tmp <- read.table(i, head = T, as.is = T, sep = "\t")
tmp <- tmp[,c("Geneset.ID", "Description", "P.value")]
#tmp$P.value <- -1 * log10(tmp$P.value)
colnames(tmp) <- c("Geneset.ID", "Description", labels[match(i, results_files)])
if(is.data.frame(all)) {
all <- join(all, tmp)
} else {
all <- tmp
}
}
head(all)
all <- ""
for(i in results_files) {
tmp <- read.table(i, head = T, as.is = T, sep = "\t")
tmp <- tmp[,c("Geneset.ID", "Description", "P.value")]
#tmp$P.value <- -1 * log10(tmp$P.value)
colnames(tmp) <- c("Geneset.ID", "Description", labels[match(i, results_files)])
head(tmp[tmp$Geneset.ID=="GO:0008104",])
if(is.data.frame(all)) {
all <- join(all, tmp)
} else {
all <- tmp
}
}
all <- ""
for(i in results_files) {
tmp <- read.table(i, head = T, as.is = T, sep = "\t")
tmp <- tmp[,c("Geneset.ID", "Description", "P.value")]
#tmp$P.value <- -1 * log10(tmp$P.value)
colnames(tmp) <- c("Geneset.ID", "Description", labels[match(i, results_files)])
print(head(tmp[tmp$Geneset.ID=="GO:0008104",]))
if(is.data.frame(all)) {
all <- join(all, tmp)
} else {
all <- tmp
}
}
results_files
all <- ""
for(i in results_files) {
tmp <- read.table(i, head = T, as.is = T, sep = "\t")
tmp <- tmp[,c("Geneset.ID", "Description", "P.value")]
#tmp$P.value <- -1 * log10(tmp$P.value)
colnames(tmp) <- c("Geneset.ID", "Description", labels[match(i, results_files)])
nrow(tmp)
print(head(tmp[tmp$Geneset.ID=="GO:0008104",]))
if(is.data.frame(all)) {
all <- join(all, tmp)
} else {
all <- tmp
}
}
all <- ""
for(i in results_files) {
tmp <- read.table(i, head = T, as.is = T, sep = "\t")
tmp <- tmp[,c("Geneset.ID", "Description", "P.value")]
#tmp$P.value <- -1 * log10(tmp$P.value)
colnames(tmp) <- c("Geneset.ID", "Description", labels[match(i, results_files)])
tmp[115,]
nrow(tmp)
print(head(tmp[tmp$Geneset.ID=="GO:0008104",]))
if(is.data.frame(all)) {
all <- join(all, tmp)
} else {
all <- tmp
}
}
all <- ""
for(i in results_files) {
tmp <- read.table(i, head = T, as.is = T, sep = "\t")
tmp <- tmp[,c("Geneset.ID", "Description", "P.value")]
#tmp$P.value <- -1 * log10(tmp$P.value)
colnames(tmp) <- c("Geneset.ID", "Description", labels[match(i, results_files)])
print(tmp[115,])
print(nrow(tmp))
print(head(tmp[tmp$Geneset.ID=="GO:0008104",]))
if(is.data.frame(all)) {
all <- join(all, tmp)
} else {
all <- tmp
}
}
all <- ""
for(i in results_files) {
tmp <- read.table(i, head = T, as.is = T, sep = "\t")
tmp <- tmp[,c("Geneset.ID", "Description", "P.value")]
#tmp$P.value <- -1 * log10(tmp$P.value)
colnames(tmp) <- c("Geneset.ID", "Description", labels[match(i, results_files)])
print(tmp[114,])
print(nrow(tmp))
print(head(tmp[tmp$Geneset.ID=="GO:0008104",]))
if(is.data.frame(all)) {
all <- join(all, tmp)
} else {
all <- tmp
}
}
i <- results_files[2]
tmp <- read.table(i, head = T, as.is = T, sep = "\t")
all <- ""
for(i in results_files) {
tmp <- read.table(i, head = T, as.is = T, sep = "\t", quote = "")
tmp <- tmp[,c("Geneset.ID", "Description", "P.value")]
#tmp$P.value <- -1 * log10(tmp$P.value)
colnames(tmp) <- c("Geneset.ID", "Description", labels[match(i, results_files)])
print(tmp[114,])
print(nrow(tmp))
print(head(tmp[tmp$Geneset.ID=="GO:0008104",]))
if(is.data.frame(all)) {
all <- join(all, tmp)
} else {
all <- tmp
}
}
head(all)
is.na(all[,3])
sum(!is.na(all[,3]))
sum(is.na(all[,3]))
sum(is.na(all[,4]))
sum(is.na(all[,5]))
all <- ""
for(i in results_files) {
tmp <- read.table(i, head = T, as.is = T, sep = "\t", quote = "")
tmp <- tmp[,c("Geneset.ID", "Description", "P.value")]
tmp$P.value <- -1 * log10(tmp$P.value)
colnames(tmp) <- c("Geneset.ID", "Description", labels[match(i, results_files)])
if(is.data.frame(all)) {
all <- join(all, tmp)
} else {
all <- tmp
}
}
#####  MAKE THE PLOTS  #####
# ditch unnecessary columns
all <- all[,!colnames(all) %in% c("Geneset.ID", "Description")]
# reshape the data.frame
all <- tidyr::gather(all, key = category, value, grep("current", colnames(all), invert = T))
# plot
p <- ggplot(all) + geom_point(aes(x = current, y = value)) + facet_wrap( ~ category) + geom_abline(aes(color = "red", type = "dashed"), slope = 1, intercept = 0)
p
all <- all[,!colnames(all) %in% c("Geneset.ID", "Description")]
head(all)
max(all$current)
max(all$value)
max_val <- max(c(max(all$current), max(all$value)))
max_val
p <- ggplot(all) + geom_point(aes(x = current, y = value)) + facet_wrap( ~ category) + geom_abline(aes(color = "red", type = "dashed"), slope = 1, intercept = 0) + xlim(c(0, max_val*1.1)) + ylim(c(0, max_val*1.1))
p
p <- ggplot(all) + geom_point(aes(x = current, y = value)) + facet_wrap( ~ category) + geom_abline(color = "red", type = "dashed", slope = 1, intercept = 0) + xlim(c(0, max_val*1.1)) + ylim(c(0, max_val*1.1))
p
p <- ggplot(all) + geom_point(aes(x = current, y = value)) + facet_wrap( ~ category) + geom_abline(color = "red", linetype = "dashed", slope = 1, intercept = 0) + xlim(c(0, max_val*1.1)) + ylim(c(0, max_val*1.1))
p
library(qvalue)
1007415 - 1005248
(1007415 - 1005248) / 1007415
